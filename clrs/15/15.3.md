## 15.3-2 Why Mergesort can't be sped up with DP?

Example:

```
4 3 2 1 4 3 2 1 4 3 2 1 4 3 2 1
4 3 2 1 4 3 2 1 ...
4 3 2 1  4 3 2 1 ...
4 3  2 1  4 3 2 1 ...
3 4  1 2  4 3 2 1 ...
1 2 3 4  4 3 2 1 (memoization) ... 
1 2 3 4  1 2 3 4 ...
1 1 2 2 3 3 4 4  4 3 2 1 4 3 2 1 (memoization)
1 1 2 2 3 3 4 4  1 1 2 2 3 3 4 4
1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 

```

Problem, memoization. How to store solutions to previously solved? How to compute hash? Key storage: O(n), value: O(n). Compute hash time: O(n). It needs to iterate subproblem elements before solving it recursively to determine that the same problem solved before. Space proposonal to $(n+nlog(n))$. 


## 15.3-3

> Consider a variant of the matrix-chain multiplication problem in which the goal is to parenthesize the sequence of matrices so as to maximize, rather than minimize, the number of scalar multiplications. Does this problem exhibit optimal substructure?

Yes, because optimal solution will consist of optimal solutions to subproblems, i.e. $$m[i,j] = max \left\{ m[i,k] + p_{i-1} p_j p_k + m[k+1,j] \right\} $$ for $k = i,..,j-1$


## 15.3-4

> Can we find an optimal solution without solving subproblems before by choosing k with min $p_{i-1} p_k p_j$ ? Contra-example?

Example: 
$A_1, A_2, A_3, A_4 = 1000,100,20,10,1000$ 

Greedy: $((A_1 A_2)A_3)A_4$. Total calculations = 1220e4.

DP: $(A_1 (A_2A_3))A_4$. Total: 1102e4.


